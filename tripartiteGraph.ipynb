{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0ed3e6e-9a55-41d2-8632-b7e1af68459d",
   "metadata": {},
   "source": [
    "<a id='table_of_contents'></a>\n",
    "\n",
    "0. [Import Libraries](#imports)\n",
    "1. [Custom Dataset](#dataset)\n",
    "2. [Generate Random Inputs](#inputs)\n",
    "3. [Hyperparameters](#hparams)\n",
    "4. [Define the Tripartite Graph Model](#model)<br>\n",
    "5. [Train the Model](#training)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eaad09-788b-4877-882b-16ce006af760",
   "metadata": {},
   "source": [
    "# 0. Import Necessary Libraries <a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61af0bf-2c8c-4b60-81de-dcdf2162ce25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe664e84-5e23-4e58-b2fc-04b73ed91b79",
   "metadata": {},
   "source": [
    "# 1. Custom Dataset <a id='dataset'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb395f89-11b1-4dfc-afcc-77b9291da035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TripartiteData(Data):\n",
    "    def __init__(self, vc_edge=None, vo_edge=None, co_edge=None, x_v=None, x_c=None, x_o=None, y=None, c_ind=None):\n",
    "        super().__init__()\n",
    "        self.vc_edge = vc_edge\n",
    "        self.vo_edge = vo_edge\n",
    "        self.co_edge = co_edge\n",
    "        self.x_v = x_v\n",
    "        self.x_c = x_c\n",
    "        self.x_o = x_o\n",
    "        self.y = y\n",
    "        self.c_ind = c_ind\n",
    "        \n",
    "    def __inc__(self, key, value, *args, **kwargs):   # incremental count between two consecutive graph attributes\n",
    "        if key == 'vc_edge':\n",
    "            return torch.tensor([[self.x_c.size(0)], [self.x_v.size(0)]])\n",
    "        if key == 'vo_edge':\n",
    "            return torch.tensor([[self.x_o.size(0)], [self.x_v.size(0)]])\n",
    "        if key == 'co_edge':\n",
    "            return torch.tensor([[self.x_o.size(0)], [self.x_c.size(0)]])\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)\n",
    "        \n",
    "    def __cat_dim__(self, key, value, *args, **kwargs): # defines in which dimension graph tensors will be concatenated together\n",
    "        if key == 'vc_edge':\n",
    "            return 1\n",
    "        if key == 'vo_edge':\n",
    "            return 1\n",
    "        if key == 'co_edge':\n",
    "            return 1\n",
    "        if key == 'c_ind':\n",
    "            return 1\n",
    "        else:\n",
    "            return super().__cat_dim__(key, value, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9aae4-44e8-4fa6-afec-b952a32843d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize(value):  # row-normalize feature matrix\n",
    "    value = value - value.min()\n",
    "    value.div_(value.sum(dim=-1, keepdim=True).clamp_(min=1.))\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf19871-0a7f-4ee1-a9a1-df03c5227880",
   "metadata": {},
   "source": [
    "# 2. Generate Random Inputs <a id='inputs'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d27bee2-c46f-449c-9268-4ffe55c9b1e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# number of features for variable nodes, constraint nodes and objective node, respectively\n",
    "feat_var = np.random.randint(1, 50) \n",
    "feat_cons = np.random.randint(1, 30)\n",
    "feat_obj = 1\n",
    "\n",
    "num_obj = 1 # there is only one objective node for each MILP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe1c4c-e17f-4f4f-a9dc-f3446d874033",
   "metadata": {},
   "source": [
    "### Graphs with different node numbers are generated and added to the data list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d3871-797f-425f-b773-4a5c166d3658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_list = []\n",
    "max_var_nodes = 100\n",
    "num_graphs = 500\n",
    "\n",
    "for i in range(num_graphs):\n",
    "    num_var = np.random.randint(2, max_var_nodes)\n",
    "    num_cons = np.random.randint(1, num_var) # Number of contraints has to be less than number of variables.\n",
    "    num_edges = np.random.randint(1, num_var*num_cons + 1) # between variable nodes and constraint nodes\n",
    "    \n",
    "    # EDGE INDICES (FOR EFFICIENT MEMORY USAGE) [source, destination/target]\n",
    "    vc_edge = torch.vstack((torch.randint(0, num_cons, (1, num_edges)), torch.randint(0, num_var, (1, num_edges))))\n",
    "    vc_edge = torch.unique(vc_edge, dim=1)  # remove overlapping edges\n",
    "\n",
    "    # all variables are connected to the objective node\n",
    "    vo_edge = torch.vstack((torch.zeros(1, num_var, dtype=torch.long), torch.tensor([i for i in range(num_var)]))) \n",
    "    \n",
    "    # all constraints are connected to the objective node\n",
    "    co_edge = torch.vstack((torch.zeros(1, num_cons, dtype=torch.long), torch.tensor([i for i in range(num_cons)])))\n",
    "    \n",
    "    # CREATE RANDOM INPUTS\n",
    "    # Feature matrices for variables, constraint, and the objective\n",
    "    x_v = torch.rand(num_var, feat_var, dtype=torch.float)\n",
    "    x_c = torch.rand(num_cons, feat_cons, dtype=torch.float)\n",
    "    x_o = torch.rand(num_obj, feat_obj, dtype=torch.float)\n",
    "    \n",
    "    # Create Binary Labels\n",
    "    y = torch.randint(0, 2, (num_var,), dtype=torch.float)\n",
    "    cons_indices = i * torch.ones(1, num_cons, dtype=torch.long) # It will be used for copy h_o for each h_c, then sum up\n",
    "    \n",
    "    data = TripartiteData(vc_edge, vo_edge, co_edge, normalize(x_v), normalize(x_c), x_o, y, cons_indices)\n",
    "    data.num_nodes = num_var  # num_var + num_cons + num_obj\n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513a9ce-9172-4af7-8a6d-aaca017401e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(12345)\n",
    "random.shuffle(data_list)\n",
    "\n",
    "# Split the graphs into train, validation and test sets\n",
    "train_ratio = 0.6\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "train_size = int(len(data_list)*train_ratio)\n",
    "val_size = int(len(data_list)*val_ratio)\n",
    "\n",
    "train_dataset = data_list[:train_size]\n",
    "val_dataset = data_list[train_size:train_size+val_size]\n",
    "test_dataset = data_list[train_size+val_size:]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of validation graphs: {len(val_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778e7bd9-6b44-4339-a88b-28c9f002ad07",
   "metadata": {},
   "source": [
    "# 3. Hyperparameters <a id='hparams'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fd49b-f7d7-41ec-aeea-3f485bd1264e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 64   # number of hidden layers\n",
    "T = 2    # number of transitions\n",
    "num_epochs = 100\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b313f14b-616a-4440-a0b7-425831f3a3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into mini-batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13e00bf-b2cf-4f0a-9601-5738c2adc201",
   "metadata": {},
   "source": [
    "# 4. Define the Tripartite Graph Model <a id='model'></a>\n",
    "* By Using Edge List "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a810ae-7772-4231-9540-d825c80e54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNN(nn.Module):\n",
    "    def __init__(self, h, T, num_feat):\n",
    "        super(GNN, self).__init__()\n",
    "        \n",
    "        torch.manual_seed(3)\n",
    "        self.hid = h\n",
    "        self.weights = {}\n",
    "        for i in [\"vo\", \"oc\", \"vc\", \"co\", \"ov\", \"cv\"]:\n",
    "            W = nn.init.kaiming_normal_(torch.empty(h, 2*h), nonlinearity='relu')\n",
    "            self.weights[\"W_\" + i] = torch.nn.parameter.Parameter(data=W, requires_grad=True)\n",
    "\n",
    "        self.att_weight = torch.nn.parameter.Parameter(data=nn.init.xavier_uniform_(torch.empty(2*h, 1)), requires_grad=True)\n",
    "        self.fc1 = nn.Linear(2*h, 32)\n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        \n",
    "        var_feat, cons_feat, obj_feat = num_feat\n",
    "        self.emb_var = nn.Linear(var_feat, h)\n",
    "        self.emb_cons = nn.Linear(cons_feat, h)\n",
    "        self.emb_obj = nn.Linear(obj_feat, h)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x, edge_indices, batch, c_ind):\n",
    "        x_v, x_c, x_o = x\n",
    "        vc_edge, vo_edge, co_edge = edge_indices\n",
    "        num_cons = x_c.shape[0]\n",
    "        num_var = x_v.shape[0]\n",
    "        h_v = self.emb_var(x_v)\n",
    "        h_c = self.emb_cons(x_c)\n",
    "        h_o = self.emb_obj(x_o)\n",
    "        h_v_init = torch.clone(h_v)\n",
    "        _, counts = torch.unique_consecutive(c_ind.reshape(-1), return_counts=True)\n",
    "        \n",
    "        for t in range(T):\n",
    "            alpha_vo = self.attentions(vo_edge, h_v, h_o)\n",
    "            h_o = torch.matmul(torch.cat((h_o, torch.matmul(alpha_vo, h_v)), dim=1), self.weights[\"W_vo\"].t())\n",
    "            h_o = self.relu(h_o)\n",
    "            \n",
    "            alpha_vc = self.attentions(vc_edge, h_v, h_c)\n",
    "            # h_oc = self.relu(torch.matmul(torch.cat((h_o.tile((num_cons, 1)), h_c), dim=1), self.weights[\"W_oc\"].t()))\n",
    "            h_oc = self.relu(torch.matmul(torch.cat((torch.repeat_interleave(h_o, counts, dim=0), h_c), dim=1), self.weights[\"W_oc\"].t()))\n",
    "            h_c = self.relu(torch.matmul(torch.cat((h_oc, torch.matmul(alpha_vc, h_v)), dim=1), self.weights[\"W_vc\"].t()))\n",
    "            \n",
    "            alpha_co = self.attentions(co_edge, h_c, h_o)\n",
    "            h_o = self.relu(torch.matmul(torch.cat((h_o, torch.matmul(alpha_co, h_c)), dim=1), self.weights[\"W_co\"].t()))\n",
    "            \n",
    "            alpha_cv = self.attentions((vc_edge[1], vc_edge[0]), h_c, h_v) \n",
    "            h_ov = self.relu(torch.matmul(torch.cat((torch.repeat_interleave(h_o, batch.bincount(), dim=0), h_v), dim=1), self.weights[\"W_ov\"].t()))\n",
    "            h_v = self.relu(torch.matmul(torch.cat((h_ov, torch.matmul(alpha_cv, h_c)), dim=1), self.weights[\"W_cv\"].t()))\n",
    "                \n",
    "        logits = self.fc2(self.relu(self.fc1(torch.cat((h_v_init, h_v), dim=1))))\n",
    "        # z_v = torch.sigmoid(logits) # probabilities\n",
    "        return logits # z_v\n",
    "        \n",
    "    def attentions(self, edge_index, h_src, h_dest):\n",
    "        src_index, dest_index = edge_index\n",
    "        unnormalized_coeff = torch.matmul(torch.cat((h_src[dest_index], h_dest[src_index]), dim=1), self.att_weight)\n",
    "        unnormalized_coeff = torch.sigmoid(unnormalized_coeff)\n",
    "        e_matr = torch.zeros(h_dest.shape[0], h_src.shape[0]) # (variables, constraints)\n",
    "        e_matr[src_index, dest_index] = unnormalized_coeff.reshape(-1,)\n",
    "        e_matr = torch.where(e_matr == 0, -9e20, e_matr)\n",
    "        alpha = F.softmax(e_matr, dim=1)\n",
    "        return alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba698f8-7ee2-4757-819d-7a71dfdca69c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for name, param in model.state_dict().items():\n",
    "    # print(name)\n",
    "    # print(param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29f9f2e-27b9-413f-a4e3-46221c172ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d25247-9890-4dab-ab0f-eea4fccf0f8d",
   "metadata": {},
   "source": [
    "# 5. Train the Model <a id='training'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e71110-5581-4d4f-b075-566c7df7fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199c1a70-26e1-42a5-b6b8-344f71b75729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = GNN(h, T, num_feat=(feat_var, feat_cons, feat_obj)) # Initialize the model\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4404c29a-b3e6-48e9-9e66-432781f340dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    for data in train_loader:  # Iterate in batches over the training dataset.\n",
    "        data = data.to(device)\n",
    "        out = model((data.x_v, data.x_c, data.x_o), edge_indices=(data.vc_edge, data.vo_edge, data.co_edge), batch=data.batch, c_ind=data.c_ind)\n",
    "        loss = criterion(out, data.y.view(out.shape))  # Compute the loss.\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0          # Accuracy is not a good metric here, it is just used to set up the structure of model training.\n",
    "    for data in loader:  # Iterate in batches over the training/test dataset.\n",
    "        out = model((data.x_v, data.x_c, data.x_o), edge_indices=(data.vc_edge, data.vo_edge, data.co_edge), batch=data.batch, c_ind=data.c_ind)\n",
    "        probs = torch.sigmoid(out)\n",
    "        pred = torch.where(probs > 0.5, 1, 0)  # Use the class with highest probability.\n",
    "        correct += int((out == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, num_epochs):\n",
    "    train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
